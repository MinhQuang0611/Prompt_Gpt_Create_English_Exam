{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking text: i is smart\n",
      "--------------------------------------------------\n",
      "Trying to connect to: https://api.languagetool.org/v2/check\n",
      "Found the following potential errors:\n",
      "\n",
      "Error 1:\n",
      "- Issue: The personal pronoun “I” should be uppercase.\n",
      "- Context: \"i is smart\"\n",
      "- Suggestions: I\n",
      "- Rule: i vs. I\n",
      "\n",
      "Error 2:\n",
      "- Issue: Did you mean “am” or “will be”?\n",
      "- Context: \"i is smart\"\n",
      "- Suggestions: am, will be\n",
      "- Rule: Agreement: 'I is / you is / ... '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def check_grammar(text, language=\"en-US\", max_retries=3):\n",
    "    \"\"\"\n",
    "    Check text for grammar and spelling errors using LanguageTool API\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to check\n",
    "        language (str): Language code (default: en-US)\n",
    "        max_retries (int): Maximum number of retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        list: List of errors with suggestions\n",
    "    \"\"\"\n",
    "    # List of API endpoints to try\n",
    "    api_urls = [\n",
    "        \"https://api.languagetool.org/v2/check\",\n",
    "        \"https://languagetool.org/api/v2/check\",\n",
    "        \"http://localhost:8081/v2/check\"  # If running local LanguageTool server\n",
    "    ]\n",
    "    \n",
    "    params = {\n",
    "        'text': text,\n",
    "        'language': language,\n",
    "        'enabledOnly': False\n",
    "    }\n",
    "    \n",
    "    for url in api_urls:\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                print(f\"Trying to connect to: {url}\")\n",
    "                response = requests.post(url, data=params, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                result = response.json()\n",
    "                \n",
    "                errors = []\n",
    "                for match in result.get('matches', []):\n",
    "                    error = {\n",
    "                        'message': match['message'],\n",
    "                        'context': match['context']['text'],\n",
    "                        'suggestions': [fix['value'] for fix in match.get('replacements', [])[:3]],\n",
    "                        'rule': match['rule']['description']\n",
    "                    }\n",
    "                    errors.append(error)\n",
    "                \n",
    "                return errors\n",
    "                \n",
    "            except requests.exceptions.ConnectionError:\n",
    "                print(f\"Connection error. Retrying... ({retries + 1}/{max_retries})\")\n",
    "                retries += 1\n",
    "                time.sleep(2)  # Wait 2 seconds before retrying\n",
    "                \n",
    "            except requests.exceptions.Timeout:\n",
    "                print(f\"Request timed out. Retrying... ({retries + 1}/{max_retries})\")\n",
    "                retries += 1\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error with {url}: {str(e)}\")\n",
    "                break  # Try next URL\n",
    "                \n",
    "        print(f\"Failed to connect to {url}, trying next endpoint...\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def print_errors(errors):\n",
    "    \"\"\"\n",
    "    Print errors in a readable format\n",
    "    \n",
    "    Args:\n",
    "        errors (list): List of errors from check_grammar()\n",
    "    \"\"\"\n",
    "    if errors is None:\n",
    "        print(\"\\nKhông thể kết nối với API. Vui lòng thử lại sau.\")\n",
    "        return\n",
    "        \n",
    "    if not errors:\n",
    "        print(\"No errors found!\")\n",
    "        return\n",
    "        \n",
    "    print(\"Found the following potential errors:\\n\")\n",
    "    for i, error in enumerate(errors, 1):\n",
    "        print(f\"Error {i}:\")\n",
    "        print(f\"- Issue: {error['message']}\")\n",
    "        print(f\"- Context: \\\"{error['context']}\\\"\")\n",
    "        if error['suggestions']:\n",
    "            print(f\"- Suggestions: {', '.join(error['suggestions'])}\")\n",
    "        print(f\"- Rule: {error['rule']}\\n\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"\"\"i is smart\"\"\"\n",
    "    print(\"Checking text:\", text)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    errors = check_grammar(text)\n",
    "    print_errors(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SpellingChecker at 0x17b6453eae0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "import tkinter as tk \n",
    "from tkinter.scrolledtext import ScrolledText \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "nltk.download(\"words\")\n",
    "\n",
    "class SpellingChecker:\n",
    "\n",
    "    def init(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.geometry(\"600x500\")\n",
    "\n",
    "        self.text = ScrolledText(self.root, font=(\"Arial\", 14))\n",
    "        self.text.bind(\"<KeyRelease>\", self.check)\n",
    "        self.text.pack()\n",
    "\n",
    "        self.old_spaces = 0\n",
    "\n",
    "        self.root.mainloop()\n",
    "    \n",
    "    def check(self, event):\n",
    "        content = self.text.get(\"1.0\", tk.END)\n",
    "        space_count = content.count(\" \")\n",
    "\n",
    "        for tag in self.text.tag_names():\n",
    "            self.text.tag_delete(tag)\n",
    "\n",
    "        if space_count != self.old_spaces:\n",
    "            self.old_spaces = space_count\n",
    "            for word in content.split(\" \"):\n",
    "                if re.sub(r\"[^\\w]\", \"\", word.lower()) not in words():\n",
    "                    position = content.find(word)\n",
    "                    self.text.tag_add(word, f\"1.{position}\", f\"1.{position + len(word)}\")\n",
    "                    self.text.tag_config(word, foreground=\"red\")\n",
    "\n",
    "SpellingChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking text:\n",
      "The deadliest virus in modern history, perhaps of all time, was the 1918 Spanish Flu. It killed about 20 to 50 million people worldwide, perhaps more. The total death toll is unknown because medical records were not kept in many areas.\n",
      "The pandemic hit during World War I and devastated military troops. In the United States, for instance, more servicemen were killed from the flu than from the war itself. The Spanish flu was fatal to a higher proportion of young adults than most flu viruses.\n",
      "The pandemic started mildly, in the spring of 1918, but was followed by a much more severe wave in the fall of 1918. The war likely contributed to the devastating mortality numbers, as large outbreaks occurred in military forces living in close quarters. Poor nutrition and the unsanitary conditions of war camps had an effect.\n",
      "A third wave occurred in the winter and spring of 1919, and a fourth, smaller wave occurred in a few areas in spring 1920. Initial symptoms of the flu were typical: sore throat, headache, and fever. The flu often progressed rapidly to cause severe pneumonia and sometimes hemorrhage in the lungs and mucus membranes. A characteristic feature of severe cases of the Spanish Flu was heliotrope cyanosis, where the patient's face turned blue from lack of oxygen in the cells. Death usually followed within hours or days.\n",
      "Modern medicine such as vaccines, antivirals, and antibiotics for secondary infections were not available at that time, so medical personnel couldn't do much more than try to relieve symptoms.\n",
      "The flu ended when it had infected enough people that those who were susceptible had either died or developed immunity.\n",
      "\n",
      "Results:\n",
      "No spelling mistakes found!\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "class SpellingChecker:\n",
    "    def __init__(self):\n",
    "        self.spell = SpellChecker()\n",
    "    \n",
    "    def check_text(self, text):\n",
    "        \"\"\"\n",
    "        Check spelling in a text and return corrections\n",
    "        \"\"\"\n",
    "        # Split text into words and keep track of their positions\n",
    "        words = text.split()\n",
    "        word_positions = {}\n",
    "        \n",
    "        # Store positions for each word\n",
    "        for index, word in enumerate(words):\n",
    "            # Remove punctuation from word for checking\n",
    "            clean_word = word.strip('.,!?:;()[]{}\"\"''')\n",
    "            if clean_word not in word_positions:\n",
    "                word_positions[clean_word] = []\n",
    "            word_positions[clean_word].append(index)\n",
    "        \n",
    "        # Find misspelled words\n",
    "        misspelled = self.spell.unknown([word.strip('.,!?:;()[]{}\"\"''') for word in words])\n",
    "        \n",
    "        # Store corrections\n",
    "        corrections = []\n",
    "        for word in misspelled:\n",
    "            # Get all positions for this misspelled word\n",
    "            positions = word_positions.get(word, [])\n",
    "            \n",
    "            correction = {\n",
    "                'word': word,\n",
    "                'suggestions': list(self.spell.candidates(word)),\n",
    "                'positions': positions  # Now storing all positions\n",
    "            }\n",
    "            corrections.append(correction)\n",
    "            \n",
    "        return corrections\n",
    "\n",
    "    def print_corrections(self, text):\n",
    "        \"\"\"\n",
    "        Print spelling corrections in a formatted way\n",
    "        \"\"\"\n",
    "        try:\n",
    "            corrections = self.check_text(text)\n",
    "            \n",
    "            if not corrections:\n",
    "                print(\"No spelling mistakes found!\")\n",
    "                return\n",
    "            \n",
    "            print(f\"Found {len(corrections)} spelling mistakes:\\n\")\n",
    "            \n",
    "            for i, correction in enumerate(corrections, 1):\n",
    "                print(f\"Mistake #{i}:\")\n",
    "                print(f\"- Word: {correction['word']}\")\n",
    "                print(f\"- Suggestions: {', '.join(correction['suggestions'][:5])}\")\n",
    "                # Print all positions where the word appears\n",
    "                positions_str = ', '.join(str(pos + 1) for pos in correction['positions'])\n",
    "                print(f\"- Position(s): word #{positions_str}\")\n",
    "                print()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while checking the text: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    checker = SpellingChecker()\n",
    "    \n",
    "    test_text = \"\"\"The deadliest virus in modern history, perhaps of all time, was the 1918 Spanish Flu. It killed about 20 to 50 million people worldwide, perhaps more. The total death toll is unknown because medical records were not kept in many areas.\n",
    "The pandemic hit during World War I and devastated military troops. In the United States, for instance, more servicemen were killed from the flu than from the war itself. The Spanish flu was fatal to a higher proportion of young adults than most flu viruses.\n",
    "The pandemic started mildly, in the spring of 1918, but was followed by a much more severe wave in the fall of 1918. The war likely contributed to the devastating mortality numbers, as large outbreaks occurred in military forces living in close quarters. Poor nutrition and the unsanitary conditions of war camps had an effect.\n",
    "A third wave occurred in the winter and spring of 1919, and a fourth, smaller wave occurred in a few areas in spring 1920. Initial symptoms of the flu were typical: sore throat, headache, and fever. The flu often progressed rapidly to cause severe pneumonia and sometimes hemorrhage in the lungs and mucus membranes. A characteristic feature of severe cases of the Spanish Flu was heliotrope cyanosis, where the patient's face turned blue from lack of oxygen in the cells. Death usually followed within hours or days.\n",
    "Modern medicine such as vaccines, antivirals, and antibiotics for secondary infections were not available at that time, so medical personnel couldn't do much more than try to relieve symptoms.\n",
    "The flu ended when it had infected enough people that those who were susceptible had either died or developed immunity.\"\"\"\n",
    "    \n",
    "    print(\"Checking text:\")\n",
    "    print(test_text)\n",
    "    print(\"\\nResults:\")\n",
    "    checker.print_corrections(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Thanh Minh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-10 15:03:44,658 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, VERB, PUNCT, ADP, DET, PROPN, PRON, ADJ, ADV, CCONJ, PART, NUM, AUX, INTJ, SYM, X, <START>, <STOP>\n",
      "Sentence[4]: \"I love Berlin.\" → [\"I\"/PRON, \"love\"/VERB, \"Berlin\"/PROPN, \".\"/PUNCT]\n",
      "The following NER tags are found:\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/upos-english\")\n",
    "\n",
    "# make example sentence\n",
    "sentence = Sentence(\"I love Berlin.\")\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence\n",
    "print(sentence)\n",
    "\n",
    "# print predicted NER spans\n",
    "print('The following NER tags are found:')\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('pos'):\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependency Parse:\n",
      "Jack         nsubj        messed\n",
      "messed       ROOT         messed\n",
      "up           prt          messed\n",
      "his          poss         room\n",
      "room         dobj         messed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7a8ed4786e80462a904edcb19d754a26-0\" class=\"displacy\" width=\"650\" height=\"242.0\" direction=\"ltr\" style=\"max-width: none; height: 242.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"162.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Jack</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"162.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">messed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"162.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">up</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"162.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">his</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"162.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">room</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a8ed4786e80462a904edcb19d754a26-0-0\" stroke-width=\"2px\" d=\"M70,122.0 C70,62.0 165.0,62.0 165.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a8ed4786e80462a904edcb19d754a26-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,124.0 L70,120.0 70,120.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a8ed4786e80462a904edcb19d754a26-0-1\" stroke-width=\"2px\" d=\"M190,122.0 C190,62.0 285.0,62.0 285.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a8ed4786e80462a904edcb19d754a26-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M285.0,124.0 L285.0,120.0 285.0,120.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a8ed4786e80462a904edcb19d754a26-0-2\" stroke-width=\"2px\" d=\"M430,122.0 C430,62.0 525.0,62.0 525.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a8ed4786e80462a904edcb19d754a26-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,124.0 L430,120.0 430,120.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a8ed4786e80462a904edcb19d754a26-0-3\" stroke-width=\"2px\" d=\"M190,122.0 C190,2.0 530.0,2.0 530.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a8ed4786e80462a904edcb19d754a26-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M530.0,124.0 L530.0,120.0 530.0,120.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msyntax_tree.html\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     33\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m    <html>\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m    <head>\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124m        <div class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msyntax-tree\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124m        </div>\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124m    </body>\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m    </html>\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Print detailed syntactic analysis\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"Jack messed up his room\")\n",
    "\n",
    "# Print dependency information\n",
    "print(\"\\nDependency Parse:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:12} {token.dep_:12} {token.head.text}\")\n",
    "\n",
    "# Configure visualization options\n",
    "options = {\n",
    "    \"compact\": False,\n",
    "    \"bg\": \"#ffffff\",\n",
    "    \"color\": \"#000000\",\n",
    "    \"font\": \"Arial\",\n",
    "    \"arrow_spacing\": 20,\n",
    "    \"arrow_width\": 2,\n",
    "    \"distance\": 120,\n",
    "    \"offset_x\": 50,\n",
    "    \"word_spacing\": 40,\n",
    "}\n",
    "\n",
    "# Generate and display syntax tree visualization\n",
    "html = displacy.render(doc, style=\"dep\", options=options)\n",
    "\n",
    "# Save visualization to file\n",
    "with open(\"syntax_tree.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Syntax Tree</title>\n",
    "        <style>\n",
    "            body { margin: 20px; }\n",
    "            .syntax-tree { border: 1px solid #ccc; padding: 20px; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"syntax-tree\">\n",
    "    \"\"\")\n",
    "    f.write(html)\n",
    "    f.write(\"\"\"\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\")\n",
    "\n",
    "# Print detailed syntactic analysis\n",
    "print(\"\\nDetailed Syntactic Analysis:\")\n",
    "for token in doc:\n",
    "    print(f\"\"\"\n",
    "Token: {token.text}\n",
    "    Dependency: {token.dep_}\n",
    "    Head word: {token.head.text}\n",
    "    Part of speech: {token.pos_}\n",
    "    Syntactic tag: {token.tag_}\n",
    "    Detailed tag: {spacy.explain(token.tag_)}\n",
    "    Dependency explanation: {spacy.explain(token.dep_)}\n",
    "    Children: {[child.text for child in token.children]}\n",
    "    \"\"\")\n",
    "\n",
    "# Print phrase structure\n",
    "print(\"\\nPhrase Structure:\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"\"\"\n",
    "Noun Phrase: {chunk.text}\n",
    "    Root text: {chunk.root.text}\n",
    "    Root dep_: {chunk.root.dep_}\n",
    "    Root head text: {chunk.root.head.text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
